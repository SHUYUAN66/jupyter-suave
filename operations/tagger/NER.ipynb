{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style=\"color:red\">Named Entity Recognition for SuAVE</span></h1>\n",
    "\n",
    "This notebook uses spaCy to generate named entity tags by parsing a selected text field in a SuAVE dataset\n",
    "See https://spacy.io/ for more information.\n",
    "\n",
    "The following tags are generated and added as #multi variables to survey datafile (from https://spacy.io/api/annotation#named-entities), if they exist in text:\n",
    "\n",
    "   * PERSON:\tPeople, including fictional.\n",
    "   * NORP:\tNationalities or religious or political groups.\n",
    "   * FAC:\tBuildings, airports, highways, bridges, etc.\n",
    "   * ORG:\tCompanies, agencies, institutions, etc.\n",
    "   * GPE:\tCountries, cities, states.\n",
    "   * LOC:\tNon-GPE locations, mountain ranges, bodies of water.\n",
    "   * PRODUCT:\tObjects, vehicles, foods, etc. (Not services.)\n",
    "   * EVENT:\tNamed hurricanes, battles, wars, sports events, etc.\n",
    "   * WORK_OF_ART:\tTitles of books, songs, etc.\n",
    "   * LAW:\tNamed documents made into laws.\n",
    "   * LANGUAGE:\tAny named language.\n",
    "   * DATE:\tAbsolute or relative dates or periods.\n",
    "\n",
    "\n",
    "Additionally, users have an option to add user-defined dictionaries of terms, and add custom #multi variables with terms from the dictionary. These cells are optional. Users can also load larger pre-trained NER models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing:\n",
    "\n",
    "http://localhost:8888/notebooks/Downloads/jupyter-suave/operations/tagger/NER.ipynb?surveyurl=http://suave-dev.sdsc.edu/main/file=spatialsuave_Russian_FB_Ads_w_Concepts.csv&views=1110001&view=grid&user=spatialsuave&csv=spatialsuave_Russian_FB_Ads_w_Concepts.csv&params=none&dzc=https://maxim.ucsd.edu/dzgen/lib-staging-uploads/bea6f8abb86c98ef168775a159612828/content.dzc&activeobject=null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieve survey parameters from the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "function getQueryStringValue (key)\n",
    "{  \n",
    "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
    "}\n",
    "IPython.notebook.kernel.execute(\"survey_url='\".concat(getQueryStringValue(\"surveyurl\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"views='\".concat(getQueryStringValue(\"views\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"view='\".concat(getQueryStringValue(\"view\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"user='\".concat(getQueryStringValue(\"user\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"csv_file='\".concat(getQueryStringValue(\"csv\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"dzc_file='\".concat(getQueryStringValue(\"dzc\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"params='\".concat(getQueryStringValue(\"params\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"active_object='\".concat(getQueryStringValue(\"activeobject\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"full_notebook_url='\" + window.location + \"'\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the environment (if needed) and importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">Skip this cell if the spaCy enviroment is already set up. Otherwise, un-comment and run the following commands to set up the environment.  </span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Install the main module (see https://spacy.io/)\n",
    "# ! pip install spacy\n",
    "\n",
    "#### lemmatization - only needed if creating a model from scratch\n",
    "# !pip install -U spacy-lookups-data\n",
    "\n",
    "####  Need to install one of these models\n",
    "# !python -m spacy download en_core_web_lg   # 789 mb\n",
    "# !python -m spacy download en_core_web_md   # 91 mb\n",
    "# !python -m spacy download en_core_web_sm   # 11 mb\n",
    "\n",
    "#### Installing these models via pip (see https://pypi.org/project/spacy/)\n",
    "    \n",
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz    \n",
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz    \n",
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import spacy and other libraries, load the default pre-trained spacy model (small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "# Importing additional libraries\n",
    "import panel as pn\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Loading extensions\n",
    "pn.extension()\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "absolutePath = \"../../temp_csvs/\"\n",
    "url_partitioned = full_notebook_url.partition('/operations')\n",
    "base_url = url_partitioned[0];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Currently installed is en_core_web_sm model version 2.2.5. It's size is 11 mb\n",
    "# To update the small model (en_core_web_sm), uncomment and run \n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "# load the small model:\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slider(data):\n",
    "    \"\"\"\n",
    "    slider creates an interactive display of a\n",
    "    data frame.\n",
    "    \n",
    "    :param df: data frame\n",
    "    :returns: interactive dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Row Selector widget\n",
    "    row_selection = pn.widgets.IntSlider(name='Navigate Rows', width=350, \n",
    "                                         margin=(0,50,-15,0), end=len(df)-1)\n",
    "\n",
    "    # Column Selector widget\n",
    "    col_selection = pn.widgets.IntSlider(name='Navigate Columns', width=350, \n",
    "                                         margin=(0,0,5,0), end=len(df.columns))\n",
    "    \n",
    "    @pn.depends(row_selection.param.value, col_selection.param.value)\n",
    "    def navigate_data(row=0, col=0):\n",
    "        return data.iloc[row:row+5, col:col+10]\n",
    "    \n",
    "    sliders = pn.Row(row_selection, col_selection, margin=(0,0,0,10))\n",
    "    full_widget = pn.Column(sliders, navigate_data)\n",
    "    return full_widget\n",
    "\n",
    "def extract_data(path):\n",
    "    \"\"\"\n",
    "    extract_data reads files from various formats\n",
    "    \n",
    "    :param link: string representing path to file\n",
    "    :returns: data frame of file\n",
    "    \"\"\"\n",
    "\n",
    "    # Reading file at path\n",
    "    if path.endswith(('.txt', 'tsv')):\n",
    "        try:\n",
    "            data = pd.read_csv(path, sep='\\t', encoding=\"latin-1\")\n",
    "        except UnicodeDecodeError:\n",
    "            data = pd.read_csv(path, sep='\\t', encoding=\"ISO-8859-1\")\n",
    "    elif path.endswith('.csv'):\n",
    "        try:\n",
    "            data = pd.read_csv(path, encoding=\"latin-1\")\n",
    "        except UnicodeDecodeError:\n",
    "            data = pd.read_csv(path, encoding=\"ISO-8859-1\")\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">Optionally, uncomment the lines below to install and import larger pretrained NER models. Otherwise, skip to step 3</span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Installing medium or large models will take a bit longer:\n",
    "\n",
    "#### For the medium model:\n",
    "# !python -m spacy download en_core_web_md   # 91 mb\n",
    "#### and load it using\n",
    "# import en_core_web_md\n",
    "# nlp = en_core_web_md.load()\n",
    "\n",
    "#### Or, for the large model:\n",
    "# !python -m spacy download en_core_web_lg   # 789 mb\n",
    "#### and load it using\n",
    "# import en_core_web_lg\n",
    "# nlp = en_core_web_lg.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select a survey file from SuAVE or import a local CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = pn.widgets.RadioBoxGroup(name='Select notebook', options=['Load survey file from SuAVE', \n",
    "                                                                        'Import a local CSV file'], \n",
    "                                       inline=False)\n",
    "data_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = pn.widgets.FileInput()\n",
    "    \n",
    "def check_selection():\n",
    "    if data_select.value == 'Load survey file from SuAVE':\n",
    "        global fname\n",
    "        fname = absolutePath + csv_file\n",
    "        printmd(\"<b><span style='color:red'>SuAVE survey will be loaded. Continue to step 4.</span></b>\")\n",
    "\n",
    "    else:\n",
    "        message = pn.pane.HTML(\"<b><span style='color:red'>Upload data and continue to step 4.</span></b>\")\n",
    "        return pn.Column(message, data_input)\n",
    "    \n",
    "check_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the data and select a text variable to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pd.isnull(data_input.filename):\n",
    "    fname = absolutePath + data_input.filename\n",
    "    data_input.save(fname)\n",
    "\n",
    "df = extract_data(fname)\n",
    "\n",
    "slider(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">4a. Optionally, in the cell below, remove those groups of terms that you don't want to extract from text</span></h2>\n",
    "Alternatively, skip to step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_labels = ['PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC','PRODUCT', 'EVENT', 'WORK_OF_ART','LAW','LANGUAGE', 'DATE']\n",
    "col_labels = ['nerPerson#multi', 'nerPopulation Group#multi', 'nerFacility#multi', 'nerOrganization#multi', 'nerAdministrative Area#multi', 'nerLocation#multi','nerProduct#multi', 'nerEvent#multi', 'nerWork of Art#multi','nerLegal Document#multi','nerLanguage#multi', 'nerDate#multi']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">4b. Optionally: add a user defined dictionary to the pipeline, and use entity matcher to generate an additional #multi variable</span></h2>\n",
    "Alternatively, skip to step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "class EntityMatcher(object):\n",
    "    name = \"entity_matcher\"\n",
    "\n",
    "    def __init__(self, nlp, terms, label):\n",
    "        patterns = [nlp.make_doc(text) for text in terms]\n",
    "        self.matcher = PhraseMatcher(nlp.vocab)\n",
    "        self.matcher.add(label, None, *patterns)\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        matches = self.matcher(doc)\n",
    "        for match_id, start, end in matches:\n",
    "            span = Span(doc, start, end, label=match_id)\n",
    "            doc.ents = list(doc.ents) + [span]\n",
    "        return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_column = \"nerAnimal#multi\"\n",
    "added_group = \"ANIMAL\"\n",
    "terms = (\"cat\", \"dog\", \"tree kangaroo\", \"giant sea spider\", \"monkey\")\n",
    "\n",
    "entity_matcher = EntityMatcher(nlp, terms, added_group)\n",
    "nlp.add_pipe(entity_matcher, after=\"ner\")\n",
    "ent_labels.append(added_group)\n",
    "col_labels.append(added_column)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate pre-defined #multi variables by doing NER over the selected text variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varcols = df.columns.tolist()\n",
    "# remove any variable names are unlikely to contain parsable text \n",
    "varcols = [x for x in varcols if '#number' not in x and '#date' not in x and '#img' not in x and '#href' not in x and '#link' not in x]\n",
    "\n",
    "# Left panel\n",
    "left_text = pn.Row(\"####Select Variables for NER\", margin=(0,0,-15,270))\n",
    "binary_selector = pn.widgets.CrossSelector(options=varcols, width=630)\n",
    "left_panel = pn.Column(left_text, binary_selector, css_classes=['widget-box'], margin=(0,30,0,0))\n",
    "\n",
    "remap_text = pn.pane.Markdown('####      Make selections and run the next cell ', width=650)\n",
    "\n",
    "# Display widgets\n",
    "widgets = pn.Row(left_panel)\n",
    "full_display = pn.Column(widgets,remap_text)\n",
    "full_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def properize(txt):\n",
    "    if len(txt) > 3:\n",
    "        txt = txt.title()\n",
    "    return txt\n",
    "def extract_entity(doc, label):\n",
    "    return '|'.join(list(set([properize(ent.text) for ent in doc.ents if ent.label_ == label])))\n",
    "def extract_all(doc):\n",
    "    data = {}\n",
    "    for col_label, ent_label in zip(col_labels, ent_labels):\n",
    "        data[col_label] = extract_entity(doc, ent_label)\n",
    "    return pd.Series(data)\n",
    "#     return pd.Series({\n",
    "#       'person': extract_entity(doc, 'PERSON'),\n",
    "#       'locs': extract_entity(doc, 'LOC'),\n",
    "#     })\n",
    "\n",
    "# Replace NA with empty in each row\n",
    "# Convert row to string\n",
    "# Join row with spaces\n",
    "concatted = df[binary_selector.value].fillna('').astype(str).dropna().apply(lambda row: ' '.join(row), axis=1)\n",
    "\n",
    "# Apply nlp and then extract\n",
    "# extracted_df = concatted.head().apply(nlp).apply(extract_all)\n",
    "extracted_df = concatted.progress_apply(nlp).apply(extract_all)\n",
    "\n",
    "df_new = pd.concat([df, extracted_df], axis=1)\n",
    "print('Dimensions:\\n --- The original df: ' +str(df.shape) +'\\n --- The ner-generated df: '+ str(extracted_df.shape)+'\\n --- The concatenated df:' +str(df_new.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize the generated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slider(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now write this back, or upload to SuAVE.\n",
    "\n",
    "# df_new.to_csv('test_multi.csv', index=None)\n",
    "# df = df_new.copy().fillna('')\n",
    "#  or\n",
    "# df_new.to_csv('test_2multi2.csv', index=None)\n",
    "df = df_new.copy().fillna('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate a new survey and open it in SuAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new filename\n",
    "\n",
    "if data_select.value == 'Import a local CSV file':\n",
    "    csv_file = data_input.filename\n",
    "\n",
    "new_file = absolutePath + csv_file[:-4]+'_v1.csv'\n",
    "printmd(\"<b><span style='color:red'>A new temporary file will be created at: </span></b>\")\n",
    "print(new_file)\n",
    "df.to_csv(new_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input survey name\n",
    "\n",
    "from IPython.display import display\n",
    "input_text = widgets.Text()\n",
    "output_text = widgets.Text()\n",
    "\n",
    "def bind_input_to_output(sender):\n",
    "    output_text.value = input_text.value\n",
    "\n",
    "# Tell the text input widget to call bind_input_to_output() on submit\n",
    "input_text.on_submit(bind_input_to_output)\n",
    "\n",
    "printmd(\"<b><span style='color:red'>Input survey name here, press Enter, and then run the next cell:</span></b>\")\n",
    "# Display input text box widget for input\n",
    "display(input_text)\n",
    "\n",
    "display(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print survey name\n",
    "survey_name = output_text.value\n",
    "printmd(\"<b><span style='color:red'>Survey Name is: </span></b>\" + survey_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "referer = survey_url.split(\"/main\")[0] +\"/\"\n",
    "upload_url = referer + \"uploadCSV\"\n",
    "new_survey_url_base = survey_url.split(user)[0]\n",
    "\n",
    "import requests\n",
    "import re\n",
    "csv = {\"file\": open(new_file, \"rb\")}\n",
    "\n",
    "if data_select.value == 'Import a local CSV file':\n",
    "    dzc_file = ''\n",
    "    views = '1110001'\n",
    "    view='grid'\n",
    "\n",
    "upload_data = {\n",
    "    'name': input_text.value,\n",
    "    'dzc': dzc_file,\n",
    "    'user':user\n",
    "}\n",
    "headers = {\n",
    "    'User-Agent': 'suave user agent',\n",
    "    'referer': referer\n",
    "}\n",
    "\n",
    "r = requests.post(upload_url, files=csv, data=upload_data, headers=headers)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    printmd(\"<b><span style='color:red'>New survey created successfully</span></b>\")\n",
    "    regex = re.compile('[^0-9a-zA-Z_]')\n",
    "    s_url = survey_name\n",
    "    s_url =  regex.sub('_', s_url)\n",
    "\n",
    "    url = new_survey_url_base + user + \"_\" + s_url + \".csv\" + \"&views=\" + views + \"&view=\" + view\n",
    "    print(url)\n",
    "    printmd(\"<b><span style='color:red'>Click the URL to open the new survey</span></b>\")\n",
    "else:\n",
    "    printmd(\"<b><span style='color:red'>Error creating new survey. Check if a survey with this name already exists.</span></b>\")\n",
    "    printmd(\"<b><span style='color:red'>Reason: </span></b>\"+ str(r.status_code) + \" \" + r.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
